
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>GMM &#8212;  </title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="http://econometria.luischanci.com/content/Ch_GMM/GMM.html" />
    <link rel="shortcut icon" href="../../_static/icon.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Bibliografía" href="../zbibliography.html" />
    <link rel="prev" title="Rincón de Práctica Stata" href="../Ch_Panel/pract_panel_stata.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-136801897-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title"> </h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Bienvenida
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Series de Tiempo
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Ch_TS/VAR.html">
   Series de Tiempo
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Datos en Panel
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Ch_Panel/Panel.html">
   Datos en Panel
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Ch_Panel/pract_panel_r.html">
   Rincón de Práctica R
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Ch_Panel/pract_panel_stata.html">
   Rincón de Práctica Stata
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  GMM
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   GMM
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Referencias
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../zbibliography.html">
   Bibliografía
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/Ch_GMM/GMM.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   Introducción
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metodo-de-momentos-mm">
   Método de Momentos (MM)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metodo-generalizado-de-momentos-gmm">
   Método Generalizado de Momentos (GMM)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#formulacion-de-hansen">
     Formulación de Hansen:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-identificacion">
     (Sobre) Identificación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#otros-estimadores-vistos-como-casos-de-gmm">
     Otros estimadores vistos como casos de GMM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matriz-optima-de-ponderadores-w">
     Matriz Óptima de Ponderadores (
     <span class="math notranslate nohighlight">
      \(W\)
     </span>
     )
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#distribucion-asintotica">
     Distribución Asintótica
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#test-para-restricciones-de-sobre-identificacion">
       Test para restricciones de sobre identificación
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>GMM</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduccion">
   Introducción
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metodo-de-momentos-mm">
   Método de Momentos (MM)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#metodo-generalizado-de-momentos-gmm">
   Método Generalizado de Momentos (GMM)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#formulacion-de-hansen">
     Formulación de Hansen:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sobre-identificacion">
     (Sobre) Identificación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#otros-estimadores-vistos-como-casos-de-gmm">
     Otros estimadores vistos como casos de GMM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#matriz-optima-de-ponderadores-w">
     Matriz Óptima de Ponderadores (
     <span class="math notranslate nohighlight">
      \(W\)
     </span>
     )
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#distribucion-asintotica">
     Distribución Asintótica
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#test-para-restricciones-de-sobre-identificacion">
       Test para restricciones de sobre identificación
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="gmm">
<h1>GMM<a class="headerlink" href="#gmm" title="Permalink to this headline">¶</a></h1>
<p><strong>Método Generalizado de Momentos (<em>Generalized Method of Moments</em>)</strong></p>
<div class="section" id="introduccion">
<h2>Introducción<a class="headerlink" href="#introduccion" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Hasta ahora, MLE:</p>
<ul>
<li><p>Conjunto de obs., <span class="math notranslate nohighlight">\(\{y_i\}\)</span>, cuya pdf depende de <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
<li><p>MLE selecciona el <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> a partir del valor para el cual hay mayor probabilidad de observar el conjunto de datos.</p></li>
<li><p>Se requiere la forma la verosimilitud (basado en la función de distribución de probabilidad - pdf).</p></li>
</ul>
</li>
<li><p>Ahora pasamos a revisar otra alternativa: GMM <span id="id1">[<a class="reference internal" href="../zbibliography.html#id3">Hansen, 1982</a>]</span></p></li>
<li><p>Clave: requiere especificación de solo ciertos momentos en vez de la pdf completa.</p></li>
</ul>
</div>
<div class="section" id="metodo-de-momentos-mm">
<h2>Método de Momentos (MM)<a class="headerlink" href="#metodo-de-momentos-mm" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p>Ejemplo:</p>
<ul>
<li><p>Sea <span class="math notranslate nohighlight">\(y_i\sim t-student(\nu)\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{eqnarray*} f(y|\nu)=\frac{\Gamma((\nu+1)/2)}{(\pi y)^{1/2}\Gamma(\nu/2)}(1+(y^2/\nu))^{-(\nu+1)/2} \end{eqnarray*}\]</div>
</li>
<li><p>Disponemos de la información <span class="math notranslate nohighlight">\(\{y_i\}\)</span> y se quiere estimar <span class="math notranslate nohighlight">\(\nu\)</span></p></li>
<li><p>En MLE se obtendría el estimador a partir de la maximización de <span class="math notranslate nohighlight">\(l=\sum_ilog f(y_i|\nu)\)</span>.</p></li>
<li><p>Ahora, en MM:</p>
<ul>
<li><p>Considerando que <span class="math notranslate nohighlight">\(\nu&gt;2\)</span>, estándar <span class="math notranslate nohighlight">\(t\)</span> tiene <span class="math notranslate nohighlight">\(\mathbb{E}(y)=0\)</span> y <span class="math notranslate nohighlight">\(\mathbb{E}(y^2)=\nu/(\nu-2)\)</span>. A medida que <span class="math notranslate nohighlight">\(\nu→∞\)</span>, <span class="math notranslate nohighlight">\(var→1\)</span>, <span class="math notranslate nohighlight">\(f(\cdot)\rightarrow N(0,1)\)</span>.</p></li>
<li><p>Sea <span class="math notranslate nohighlight">\(\hat{\mu}_2=(1/N)\sum_i{y_i^2}\)</span>, para <span class="math notranslate nohighlight">\(N\rightarrow\infty\)</span>,</p>
<div class="math notranslate nohighlight">
\[\hat{\mu}_2\rightarrow_p\mathbb{E}(y^2)\]</div>
<p>por ende, un estimador consistente para <span class="math notranslate nohighlight">\(\nu\)</span> sería</p>
<div class="math notranslate nohighlight">
\[\frac{\nu}{\nu-2}=\hat{\mu}_2\]</div>
<p>en otras palabras,</p>
<div class="math notranslate nohighlight">
\[\frac{2\hat{\mu}_2}{\hat{\mu}_2-1}\]</div>
<p>(definido para <span class="math notranslate nohighlight">\(\hat{\mu}_2&gt;1\)</span>).</p>
</li>
<li><p>Este estimador es conocido como el <strong>estimador clásico de momentos (<em>the classical method of moments estimator</em>)</strong>.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Idea general:</p>
<p>Dado un vector desconocido de parámetros <span class="math notranslate nohighlight">\(\theta_{k\times1}\)</span>, suponga que se pueden computar <span class="math notranslate nohighlight">\(k\)</span> diferentes momento poblacionales asociados a la variable aleatoria <span class="math notranslate nohighlight">\(y\)</span> como una función de <span class="math notranslate nohighlight">\(\theta\)</span>, tal que</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}(y_i^j)=\mu_j(\theta)\hspace{0.4cm}para\,\,\,j=\{j_1,...,j_k\}\]</div>
<p>El estimador clásico de momentos de <span class="math notranslate nohighlight">\(\theta\)</span> es el valor de <span class="math notranslate nohighlight">\(\hat{\theta}_N\)</span> para el cual los momentos poblacionales son igualados a los muestrales: <span class="math notranslate nohighlight">\(\mu_j(\hat{\theta}_N)=\frac{\sum y_i^j}{N}\)</span>.</p>
</li>
</ul>
</div>
<div class="section" id="metodo-generalizado-de-momentos-gmm">
<h2>Método Generalizado de Momentos (GMM)<a class="headerlink" href="#metodo-generalizado-de-momentos-gmm" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p>Ejemplo:</p>
<p>En el caso anterior de la <span class="math notranslate nohighlight">\(t-student\)</span> empleamos un solo momento para obtener <span class="math notranslate nohighlight">\(\nu\)</span>. Sin embargo, es posible querer usar algunos momentos diferentes. Por ejemplo, el cuarto momento:</p>
</li>
</ul>
<div class="math notranslate nohighlight">
\[\mu_4=\frac{3\nu^2}{(\nu-2)(\nu-4)}\]</div>
<p>para el cual esperaríamos que fuera cercano a</p>
<div class="math notranslate nohighlight">
\[\hat{\mu}_4=\left(\frac{1}{N}\right)\sum{y_i^4}\]</div>
<p>Así, al emplear dos momentos, el segundo y el cuarto, se buscaría seleccionar <span class="math notranslate nohighlight">\(\nu\)</span> tal que los valores obtenidos para los momentos a partir de la muestra fueran lo más cercano posible a las expresiones poblacionales.</p>
<p>Sin embargo, al tener dos momentos y un parámetro, se busca minimizar una función objetivo/criterio del tipo (familia <span class="math notranslate nohighlight">\(L^2\)</span>-Norm)</p>
<div class="math notranslate nohighlight">
\[Q(\nu;y_N,...,y_1)=g'\cdot W\cdot g\]</div>
<p>en donde,</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{eqnarray} g\equiv \left[\begin{array}{c} \hat{\mu}_2-\nu/(\nu-2) \\ \hat{\mu}_4-3\nu^2/[(\nu-2)(\nu-4)] \end{array}\right] \end{eqnarray}\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(W\)</span> es una matriz simetrica 2x2 definida positiva de ponderadores que reflejan la importancia que se da a (‘alcanzar’) cada momento. Ej. a mayor valor del elemento <span class="math notranslate nohighlight">\(w_{1,1}\)</span> en <span class="math notranslate nohighlight">\(W_N\)</span>, mayor es la importancia que se da a estar cercano de satisfacer <span class="math notranslate nohighlight">\(\hat{\mu}_2-\nu/(\nu-2)\)</span>. En el caso de <span class="math notranslate nohighlight">\(W=I_2\)</span>, se asigna igual importancia a los dos momentos.</p>
<div class="section" id="formulacion-de-hansen">
<h3>Formulación de Hansen:<a class="headerlink" href="#formulacion-de-hansen" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>Sea <span class="math notranslate nohighlight">\(w_i\)</span> un vector <span class="math notranslate nohighlight">\(h\times1\)</span> de variables observadas</p></li>
<li><p>Sea <span class="math notranslate nohighlight">\(\theta\)</span> un vector <span class="math notranslate nohighlight">\(k\times1\)</span> de parámetros desconocidos</p></li>
<li><p>Sea <span class="math notranslate nohighlight">\(h(\theta,w_i)\)</span> un vector <span class="math notranslate nohighlight">\(r\times1\)</span> de funciones, $<span class="math notranslate nohighlight">\(h:\,(\mathbb{R}^k\times\mathbb{R}^h)\rightarrow\mathbb{R}^r\)</span>$</p></li>
<li><p>Sea <span class="math notranslate nohighlight">\(\theta_0\)</span> el verdadero vector de parámetros, y supongamos se encuentra caracterizado por $<span class="math notranslate nohighlight">\(\mathbb{E}\{h(\theta_0,w_i)\}=0\)</span>$
llamadas también condiciones de ortogonalidad.</p></li>
<li><p>Sea <span class="math notranslate nohighlight">\(X_N=(w_N,...,w_1)\)</span> un vector <span class="math notranslate nohighlight">\(Nh\times1\)</span> que contiene todas las observaciones (la muestra de tamaño <span class="math notranslate nohighlight">\(N\)</span>).</p></li>
<li><p>Sea <span class="math notranslate nohighlight">\(g(\theta;X_N)\)</span> un vector <span class="math notranslate nohighlight">\(r\times1\)</span> de promedios de funciones de <span class="math notranslate nohighlight">\(h(\theta,w_i)\)</span>, para <span class="math notranslate nohighlight">\(g:\mathbb{R}^k\rightarrow\mathbb{R}^r\)</span>, definido por</p>
<div class="math notranslate nohighlight">
\[g(\theta,X_N)=\frac{1}{N}\sum{h(\theta;w_i)}\]</div>
</li>
<li><p>La idea en GMM es seleccionar <span class="math notranslate nohighlight">\(\theta\)</span> tal que los momentos muestrales <span class="math notranslate nohighlight">\(g(\theta;X_N)\)</span> sean cercanos a los momentos poblacionales en cero. Así, el estimador de GMM, <span class="math notranslate nohighlight">\(\hat{\theta}_N\)</span>, es el valor de <span class="math notranslate nohighlight">\(\theta\)</span> que minimiza</p></li>
</ul>
<div class="math notranslate nohighlight">
\[Q(\theta;X_N)=\left( g(\theta,X_N) \right)' W_N \left( g(\theta,X_N) \right)\]</div>
<p>con <span class="math notranslate nohighlight">\(\{W_N\}_{N=1}^\infty\)</span> como una secuencia de matrices de ponderadores, la cual puede se runa función de los datos <span class="math notranslate nohighlight">\(X_N\)</span>.</p>
<ul>
<li><p>Retomando el ejemplo (<span class="math notranslate nohighlight">\(t-student\)</span>),</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(r=2\)</span></p></li>
<li><p>el vector <span class="math notranslate nohighlight">\(h\)</span> estaría dado por</p>
<div class="math notranslate nohighlight">
\[\begin{split} h(\theta,w_i)= \left[\begin{array}{c} y_i^2-\nu/(\nu-2) \\ y_i^4-3\nu^2/[(\nu-2)(\nu-4)] \end{array}\right]\end{split}\]</div>
</li>
<li><p>el vector <span class="math notranslate nohighlight">\(g\)</span> estaría dado por</p>
<div class="math notranslate nohighlight">
\[\begin{split} g(\theta,X_N)= \frac{1}{N}\left[\begin{array}{c} \sum y_i^2-\nu/(\nu-2) \\ \sum y_i^4-3\nu^2/[(\nu-2)(\nu-4)] \end{array}\right]\end{split}\]</div>
</li>
<li><p>por ende <span class="math notranslate nohighlight">\(\hat{\nu}\)</span> se puede obtener a partir de</p>
<div class="math notranslate nohighlight">
\[\min_{\nu}{[g(\theta;X_N)]'W_N[g(\theta;X_N)]}\]</div>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="sobre-identificacion">
<h3>(Sobre) Identificación<a class="headerlink" href="#sobre-identificacion" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Si el número de parámetros <span class="math notranslate nohighlight">\(k\)</span> es el mismo que el número de condiciones de ortogonalidad <span class="math notranslate nohighlight">\(r\)</span>, la función objetivo puede, en general, reducirse a hacer <span class="math notranslate nohighlight">\(g(\hat{\theta}_N;X_N)=0\)</span>. Es decir, si <span class="math notranslate nohighlight">\(k=r\)</span>, el estimador de GMM resulta de satisfacer (o resolver) las <span class="math notranslate nohighlight">\(r\)</span> ecuaciones. En tal caso, se dice que el sistema se encuentra exactamente identificado (<span class="math notranslate nohighlight">\(k=r\)</span>).</p></li>
<li><p>El caso de <span class="math notranslate nohighlight">\(r&gt;k\)</span> sería sobre-identificación. Se involucran más condiciones de ortogonalidad de las necesarias para el número de parámetros y podría no ser posible encontrar un <span class="math notranslate nohighlight">\(\hat(\theta)\)</span> que cumpla todas las restricciones (de cero) al mismo tiempo (e.g., las <span class="math notranslate nohighlight">\(r\)</span> ecuaciones de forma separada). En otras palabras, si se tienen más condiciones de ortogonalidad en comparación al número de parámetros a estimar, <span class="math notranslate nohighlight">\(r&gt;k\)</span>, se genera sobre identificación y emplear la condición <span class="math notranslate nohighlight">\(g(\hat{\theta}_N;X_N)=0\)</span> podría no ser suficiente para identificar los parámetros.</p></li>
<li><p>En ese caso, se emplea la matriz <span class="math notranslate nohighlight">\(r\times r\)</span> de ponderadores. Así, que tan cercano se encuentre <span class="math notranslate nohighlight">\(g()\)</span> a 0 dependerá de cuanto peso se le de a una condición de ortogonalidad sobre otra en la matriz <span class="math notranslate nohighlight">\(W\)</span>.</p></li>
</ul>
</div>
<div class="section" id="otros-estimadores-vistos-como-casos-de-gmm">
<h3>Otros estimadores vistos como casos de GMM<a class="headerlink" href="#otros-estimadores-vistos-como-casos-de-gmm" title="Permalink to this headline">¶</a></h3>
<p>Algunos estimadores pueden entenderse como ejemplos particulares de GMM. Por ejemplo,</p>
<ul class="simple">
<li><p>OLS</p></li>
<li><p>IV</p></li>
<li><p>2SLS</p></li>
<li><p>Nonlinear simultaneous equations estimators</p></li>
<li><p>(muchos casos de) MLE</p></li>
</ul>
</div>
<div class="section" id="matriz-optima-de-ponderadores-w">
<h3>Matriz Óptima de Ponderadores (<span class="math notranslate nohighlight">\(W\)</span>)<a class="headerlink" href="#matriz-optima-de-ponderadores-w" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><strong>Teoría.</strong> Suponiendo que <span class="math notranslate nohighlight">\(\{h(\theta_0,w_i)\}\)</span> tiene media cero, que la matriz de varianza covarianza es dada por <span class="math notranslate nohighlight">\(\Omega_\nu=\mathbb{E}\{(h(\theta_0,w_i))(h(\theta_0,w_j))'\}\)</span>, y que las covarianzas (para series de tiempo por ejemplo) son ‘<em>absolute sumable</em>’, para <span class="math notranslate nohighlight">\(\mathbb{S}=\sum_\nu\Omega_\nu\)</span>, donde <span class="math notranslate nohighlight">\(\mathbb{S}\)</span> es la varianza asintótica de la media muestra en <span class="math notranslate nohighlight">\(h(\theta_0,w_i)\)</span></p>
<div class="math notranslate nohighlight">
\[\mathbb{S}=\lim_{N\rightarrow\infty}\,N\,\mathbb{E}\{(g(\theta_0;X_N))(g(\theta_0;X_N))'\}\]</div>
<p>por ende, el valor óptimo para <span class="math notranslate nohighlight">\(W_N\)</span> estaría dado por <span class="math notranslate nohighlight">\(\mathbb{S}^{-1}\)</span>.</p>
<p>Considerando que <span class="math notranslate nohighlight">\(\mathbb{S}\)</span> depende de <span class="math notranslate nohighlight">\(\theta\)</span>, se tendría que</p>
<div class="math notranslate nohighlight">
\[\hat{\mathbb{S}}_N\equiv \left(\frac{1}{N}\right)\sum_i[h(\hat{\theta}_N,w_i)][h(\hat{\theta}_N,w_i)]'\rightarrow_p\,\mathbb{S}\]</div>
<p>para cualquier estimador consistente de <span class="math notranslate nohighlight">\(\theta_0\)</span>.</p>
<p>Notar que, (tal vez) en palabras más simples, lo anterior quiere decir que para obtener <span class="math notranslate nohighlight">\(W_N\)</span> se necesita <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>. Pero recordemos que <span class="math notranslate nohighlight">\(W_N\)</span> es necesaria para minimizar la función oibjetivo en GMM, y por ende obtener los parámetros estimados <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>. En síntesis, !hay una circularidad!.</p>
<p></br></br></p>
</li>
<li><p><strong>Aproximación práctica.</strong> Procedimiento iterativo.</p>
<ul class="simple">
<li><p>Proponer un forma inicial para <span class="math notranslate nohighlight">\(W^{(0)}\)</span> (plantear un guess). Por ejemplo, <span class="math notranslate nohighlight">\(W^{(0)}=I\)</span>.</p></li>
<li><p>Emplear <span class="math notranslate nohighlight">\(W^{(0)}\)</span> en la función objetivo <span class="math notranslate nohighlight">\(Q\)</span> de GMM para llevar a cabo la minimización y, así, poder estimar <span class="math notranslate nohighlight">\(\theta\)</span>, obteniendo <span class="math notranslate nohighlight">\(\hat{\theta}^{(0)}\)</span>.</p></li>
<li><p>Usar <span class="math notranslate nohighlight">\(\hat{\theta}^{(0)}\)</span> para estimar <span class="math notranslate nohighlight">\(\mathbb{S}\)</span>, obteniendo <span class="math notranslate nohighlight">\(\hat{\mathbb{S}}^{(0)}\)</span>.</p></li>
<li><p>Actualizar <span class="math notranslate nohighlight">\(W\)</span> a <span class="math notranslate nohighlight">\(W^{(1)}\)</span>, con <span class="math notranslate nohighlight">\(W^{(1)}=(\hat{\mathbb{S}}^{(0)})^{-1}\)</span>, obteniendo a su vez un nuevo valor <span class="math notranslate nohighlight">\(\hat{\theta}^{(1)}\)</span>.</p></li>
<li><p>Repetir la iteración hasta que <span class="math notranslate nohighlight">\(\hat{\theta}^{(j)}\equiv \hat{\theta}^{(j+1)}\)</span>.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="distribucion-asintotica">
<h3>Distribución Asintótica<a class="headerlink" href="#distribucion-asintotica" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>Sea <span class="math notranslate nohighlight">\(\hat{\theta}_N\)</span> el valor que minimiza <span class="math notranslate nohighlight">\([g(\theta,X_N)]'\hat{\mathbb{S}}^{-1}_N[g(\theta,X_N)]\)</span></p></li>
<li><p>Por ende, el estimador obtenido de GMM es una solución al sistema:</p>
<div class="math notranslate nohighlight">
\[\left[\left.\frac{\partial g(\theta,X_N)}{\partial \theta'}\right|_{\theta=\hat{\theta}}\right] \hat{\mathbb{S}}^{-1}_N g(\hat{\theta}_N,X_N)=0\]</div>
</li>
<li><p>Considerando que <span class="math notranslate nohighlight">\(g(\theta,X_N)\)</span> es la media muestral de un proceso asociado a una media poblacional de cero, dadas algunas condiciones adiconales (por ejemplo, continuidad de <span class="math notranslate nohighlight">\(h(\cdot)\)</span>), <span class="math notranslate nohighlight">\(g(\theta,X_N)\)</span> debería satisfacer el <em>CLT</em>. Por ende,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\sqrt{N}g(\theta_0,X_N)\rightarrow_L N(0,\mathbb{S})\]</div>
<ul class="simple">
<li><p>Proposición: Sea <span class="math notranslate nohighlight">\(g(\theta_0,X_N)\)</span> diferenciable y sea <span class="math notranslate nohighlight">\(\hat{\theta}_N\)</span> el estimador de GMM (para <span class="math notranslate nohighlight">\(r\geq k\)</span>).Suponiendo que se satisface:</p>
<ul>
<li><p>a) <span class="math notranslate nohighlight">\(\hat{\theta}_N\rightarrow_p\theta_0\)</span></p></li>
<li><p>b) <span class="math notranslate nohighlight">\(\sqrt{N}g(\theta_0,X_N)\rightarrow_L N(0,\mathbb{\mathbb{S}})\)</span></p></li>
<li><p>c) <span class="math notranslate nohighlight">\(plim\left(\partial g(\cdot)/\partial\theta\right)_{\theta=\hat{\theta}_N}\equiv D'\)</span>, donde las columnas de <span class="math notranslate nohighlight">\(D\)</span> son linealmente independientes.</p></li>
</ul>
</li>
</ul>
<p>Por ende,</p>
<div class="math notranslate nohighlight">
\[\sqrt{N}(\hat{\theta}_N - \theta_0)\rightarrow_L N(0,V)\]</div>
<p>con <span class="math notranslate nohighlight">\(V=(D\mathbb{S}^{-1}D')^{-1}\)</span></p>
<div class="section" id="test-para-restricciones-de-sobre-identificacion">
<h4>Test para restricciones de sobre identificación<a class="headerlink" href="#test-para-restricciones-de-sobre-identificacion" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p><span id="id2">Hansen [<a class="reference internal" href="../zbibliography.html#id3">1982</a>]</span> propone un test para evaluar si todos los momentos muestrales <span class="math notranslate nohighlight">\(g(\hat{\theta}_N;X_N)\)</span> son cercanos a cero, tal como se esperaría si los momentos poblacionales <span class="math notranslate nohighlight">\(\mathbb{E}(h(\theta_0;w_i))\)</span> fueran verdaderamente cero.</p></li>
<li><p>Considerando que <span class="math notranslate nohighlight">\(\sqrt{N}g(\theta_0;X_N)\sim N(0,\mathbb{S})\)</span> y que <span class="math notranslate nohighlight">\(g(\hat{\theta}_N;X_N)\)</span> contiene (<span class="math notranslate nohighlight">\(r-k\)</span>) variables aleatorias (no degeneradas), un test para evaluar que las restricciones de sobreidentificación son válidas es:</p>
<div class="math notranslate nohighlight">
\[\left(\sqrt{N}g(\theta_0;X_N)\right)' \hat{\mathbb{S}}_N^{-1} \left(\sqrt{N}g(\theta_0;X_N)\right)\rightarrow_L \chi^2_{(r-k)}\]</div>
<p>En otras palabras, es básicamente un test para estudiar que tan cercano es <span class="math notranslate nohighlight">\(g(\hat{\theta}_N;X_N)\)</span> de cero. Así, si se rechaza la hipótesis nula <span class="math notranslate nohighlight">\(H_0:\,\mathbb(E)\{g(\theta_0;X_N)\}\)</span>, entonces el estimador GMM es inconsistente para <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content\Ch_GMM"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../Ch_Panel/pract_panel_stata.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Rincón de Práctica Stata</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../zbibliography.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bibliografía</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Luis Chancí<br/>
    
        &copy; Copyright 2022.<br/>
      <div class="extra_footer">
        <div>
<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png"></a>
    All content on this site (unless otherwise specified) is licensed under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0 license</a>
</div>

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>