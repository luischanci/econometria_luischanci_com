

<!DOCTYPE html>


<html lang="es" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Teoría Máxima Verosimilitud &#8212; Apuntes de Econometría</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=ac02cc09edc035673794" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=ac02cc09edc035673794" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=ac02cc09edc035673794" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=ac02cc09edc035673794"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/Ch3_MLE/MLE';</script>
    <link rel="canonical" href="http://econometria.luischanci.com/content/Ch3_MLE/MLE.html" />
    <link rel="shortcut icon" href="../../_static/icon.png"/>
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" />
    <link rel="next" title="Rincón de Práctica R" href="computer/pract_mle_r.html" />
    <link rel="prev" title="3. Máxima Verosimilitud" href="Intro_MLE.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="es"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Saltar al contenido principal</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Intro_Curso.html">1. Introducción al Curso</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Ch2_OLS/OLS.html">2. Mínimos Cuadrados - Repaso</a></li>
</ul>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="Intro_MLE.html">3. Máxima Verosimilitud</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Teoría MLE</a></li>
<li class="toctree-l2"><a class="reference internal" href="computer/pract_mle_r.html">Práctica R</a></li>
<li class="toctree-l2"><a class="reference internal" href="computer/pract_mle_stata.html">Práctica Stata</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Ch4_LDV/Intro_LDV.html">4. Variable Dependiente Limitada</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../Ch4_LDV/Binaria.html">Modelos LP, Logit y Probit</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../Ch4_LDV/Binaria/pract_binaria_stata.html">Práctica Stata</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Ch4_LDV/Binaria/pract_binaria_r.html">Práctica R</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../Ch4_LDV/Multinomial.html">Modelos de Elección Múltiple</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Ch4_LDV/Conteo.html">Modelo de Conteo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Ch4_LDV/CensuraTrunc.html">Censura, Truncamiento, Selección</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Ch5_IV/IV.html">5. Variables Instrumentales</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Ch6_GMM/GMM.html">6. Método de Momentos</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Ch7_TS/Intro_TS.html">7. Series de Tiempo</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Ch7_TS/Estacionarias.html">Series Estacionarias</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Ch7_TS/VAR.html">VAR</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Ch8_Panel/Intro_Panel.html">8. Datos en Panel</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Ch8_Panel/Panel.html">Teoría Panel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Ch8_Panel/computer/pract_panel_r.html">Práctica R</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Ch8_Panel/computer/pract_panel_stata.html">Práctica Stata</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Ch9_Causal/Intro_Causal.html">9. Inferencia Causal</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Ch9_Causal/DifinDif.html">Diff-in-Diff</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Ch9_Causal/RDD.html">RDD</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../zbibliography.html">Bibliografía</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Modo de pantalla completa"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="claro/oscuro" aria-label="claro/oscuro" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Búsqueda" aria-label="Búsqueda" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Teoría Máxima Verosimilitud</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contenido </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimador">Estimador</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#errores-estandar-distribucion-asintotica">Errores estándar (distribución asintótica)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inferencia">Inferencia.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplos">Ejemplos.</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="teoria-maxima-verosimilitud">
<h1>Teoría Máxima Verosimilitud<a class="headerlink" href="#teoria-maxima-verosimilitud" title="Permalink to this heading">#</a></h1>
<p><strong>MLE: <em>Maximum Likelihood Estimation</em></strong></p>
<section id="estimador">
<h2>Estimador<a class="headerlink" href="#estimador" title="Permalink to this heading">#</a></h2>
<p><strong>Estimador de Máxima Verosimilitud (MLE):</strong> Dado un conjunto de datos, <span class="math notranslate nohighlight">\(\{w_i\}_{i=1}^n\)</span>, se busca el vector de parámetros <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> que generen la mayor probabilidad de haber observado ese conjunto particular de datos. Es decir, el <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> que haga más <strong>verosímil</strong> (“con apariencia de verdadero”) el resultado que hemos obtenido.</p>
</br>
<center><figure>
    <img alt="../../_images/distributions.png" src="../../_images/distributions.png" width="50%" height="50%"style="margin: 15px 0 0 0">
    <figcaption>Figura: Ilustración de dos f.d.p. Fuente: Contrucción en R con datos simulados.</figcaption>
</figure></center>
</br>
<p>En particular, la especificación del estimador consta de:</p>
<ul class="simple">
<li><p>Una muestra (aleatoria): <span class="math notranslate nohighlight">\(\{w_i\}_{i=1}^n\)</span></p></li>
<li><p>Una función de probabilidad (f.d.p.) <span class="math notranslate nohighlight">\(f(w_1,…,w_n; \boldsymbol{\theta})=f(\boldsymbol{w};\boldsymbol{\theta})\)</span> (asociada a la muestra)</p></li>
</ul>
<p>Diremos entonces que el modelo esta correctamente especificado si el vector de parámetros que se emplea es el verdadero (<span class="math notranslate nohighlight">\(\theta_0\)</span>): <span class="math notranslate nohighlight">\(f(w_1,…,w_n; \theta_0)\)</span>. A su vez, llamaremos a <span class="math notranslate nohighlight">\(\theta\)</span> como un vector candidato o vector hipotético al vector de parámetros, y por ende, <span class="math notranslate nohighlight">\(f(w_1,…,w_n; \theta)\)</span> será una densidad hipotética.</p>
<p>La anterior función de distribución conjunta es empleada en ML para obtener los estimadores. La idea es encontrar el vector candidato que genere la mayor probabilidad. Se denomina a dicha función de probabilidad conjunta como función de verosimilitud ( <em>likelihood function</em> ) y la denotaremos por</p>
<div class="math notranslate nohighlight">
\[\mathcal{L}_n(\theta)=f(w;\theta)\]</div>
<p>Es de notar que, dados los datos, esta es una función que dependerá del vector de parámetros (y está afectada por <span class="math notranslate nohighlight">\(n\)</span>). Es decir, la verosimilitud es básicamente la probabilidad conjunta de los datos, evaluada en la muestra observada y vista como una función de los parámetros. Así, la función objetivo a emplear para el computo de los parámetros será la de verosimilitud.</p>
<p>La intuición detrás de MLE de ‘querer buscar parámetros que den la mayor probabilidad’ se traduce en términos matemáticos en querer maximizar la función de verosimilitud, por lo que MLE es estimador extremo. Ahora, es de anotar que dicha función de verosimilitud puede eventualmente ser fuertemente no lineal (es la distribución de probabilidad conjunta de <span class="math notranslate nohighlight">\(n\)</span> observaciones independientes), lo que puede implicar desafíos en términos numéricos (computacionales). Por ende, para ayudar en este aspecto, se emplea una transformación monótona que facilite el proceso. En particular, se toma ventaja de que la función logarítmica realiza transformaciones monótonas (e.g., para <span class="math notranslate nohighlight">\(z_1&gt;z_2\)</span>, se tiene que <span class="math notranslate nohighlight">\(ln(z_1)&gt;ln(z_2)\)</span> con <span class="math notranslate nohighlight">\((z_1,z_2)\in\mathbb{R}^{+}\)</span>). Así, considerando que el vector de parámetros que maximiza el logaritmo de la función de verosimilitud es el mismo que maximiza la la función de verosimilitud, se emplea como función objetivo a optimizar el logaritmo de la función de verosimilitud:</p>
<div class="math notranslate nohighlight">
\[\mathcal{l}_n(\boldsymbol{\theta})=ln(\mathcal{L}_n(\boldsymbol{\theta}))\]</div>
<p>Así, el vector de parámetros MLE estará dado por</p>
<div class="math notranslate nohighlight">
\[\hat{\boldsymbol{\theta}}_{MLE}=\text{arg max}_{\boldsymbol{\theta}}\,ln(f(\boldsymbol{w};\boldsymbol{\theta}))\]</div>
<p>Para despejar o resolver la expresión anterior, y encontrar el vector de parámetros estimados, se obtiene primero la función <em>Score</em> . Esta función es básicamente el gradiente de la log-likelihood (es decir, las condiciones necesarias de primer orden - <em>F.O.C.</em> ):</p>
<div class="math notranslate nohighlight">
\[S(\boldsymbol{\theta})=\frac{\partial ln(\mathcal{L}_n(\boldsymbol{\theta}))}{\partial \boldsymbol{\theta}}\]</div>
</section>
<section id="errores-estandar-distribucion-asintotica">
<h2>Errores estándar (distribución asintótica)<a class="headerlink" href="#errores-estandar-distribucion-asintotica" title="Permalink to this heading">#</a></h2>
<p>Definimos la matriz de información <span class="math notranslate nohighlight">\(I(\boldsymbol{\theta})\)</span> (o, específicamente, Matriz de Información de Fisher - <em>Fisher Information</em> ) como el producto interno del vector <em>score</em></p>
<div class="math notranslate nohighlight">
\[I(\boldsymbol{\theta})=\mathbb{E}\left\{S(\boldsymbol{\theta})\,S(\boldsymbol{\theta})'\right\}\]</div>
<p>Altos valores en <span class="math notranslate nohighlight">\(I\)</span> se asocian con que pequeños cambios en <span class="math notranslate nohighlight">\(\theta\)</span> conllevan a grandes cambios en la log-likelihood, lo que significa que hay información considerable sobre <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>Una igualdad relevante asociada a la anterior definición es la Igualdad de la Matriz de Información, en la cual</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}_f\left\{S(\boldsymbol{\theta})\,S(\boldsymbol{\theta})'|_{\boldsymbol{\theta}_0}\right\}=-\mathbb{E}_f\left\{H|_{\boldsymbol{\theta}_0}\right\}\]</div>
<p>en donde <span class="math notranslate nohighlight">\(H\)</span> es la matriz hessiana que organiza todas las derivadas parciales de segundo orden,</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{H}=\frac{\partial^2\mathcal{L}_n(\boldsymbol{\theta})}{\partial \boldsymbol{\theta} \partial \boldsymbol{\theta}'}\]</div>
<p>Bajo algunas condiciones de regularidad (que definiremos adelante), se puede obtener un estimador de la matriz de varianza y covarianza mediante la matriz hessiana evaluada en los parámetros MLE:</p>
<div class="math notranslate nohighlight">
\[\text{Var}_H(\hat{\boldsymbol{\theta}})=-\boldsymbol{H}(\hat{\boldsymbol{\theta}})^{-1}\]</div>
<p>alternativamente, empleando la matriz de información,</p>
<div class="math notranslate nohighlight">
\[\text{Var}(\hat{\boldsymbol{\theta}})=I(\hat{\boldsymbol{\theta}})^{-1}\]</div>
<p><strong>Distribución asintótica.</strong> Bajo los siguientes supuestos (o condiciones)</p>
<ul>
<li><p>El proceso generador de los datos es la densidad condicional <span class="math notranslate nohighlight">\(f(\cdot)\)</span> empleada para definir la función de verosimilitud.</p></li>
<li><p>la función de densidad satisface <span class="math notranslate nohighlight">\(f(w_i,\boldsymbol{\theta}^{(1)})=f(w_i,\boldsymbol{\theta}^{(2)})\)</span> si y solo si <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(1)}=\boldsymbol{\theta}^{(2)}\)</span> .</p></li>
<li><p>La matriz</p>
<div class="math notranslate nohighlight">
\[\text{plim }n^{-1} H(\boldsymbol{\theta})\]</div>
<p>existe y es no singular.</p>
</li>
<li><p>Las operaciones de diferenciación e integración de la función (log) verosimilitud son reversibles.</p></li>
</ul>
<p>entonces,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}\)</span> es un estimadores consistente de <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>.</p></li>
<li><p>converge a tasa <span class="math notranslate nohighlight">\(\sqrt{n}\)</span> a una distribución normal</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\hat{\boldsymbol{\theta}}\sim\mathbb{N}\left(\boldsymbol{\theta},-\boldsymbol{H}(\boldsymbol{\theta})^{-1} \right)\]</div>
<p>A partir de lo anterior, dos propiedades a resaltar del MLE son:</p>
<ul>
<li><p><strong>Efficiencia.</strong> <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}_{MLE}\)</span> alcanza la cota inferior de Cramer-Rao,</p>
<div class="math notranslate nohighlight">
\[Var(\hat{\boldsymbol{\theta}}_{MLE}(\boldsymbol{w}))\geq [I(\boldsymbol{\theta}_0)]^{-1}\]</div>
</li>
<li><p><strong>Invarianza.</strong> Si <span class="math notranslate nohighlight">\(\gamma=g(\boldsymbol{\theta})\)</span>, se tiene que <span class="math notranslate nohighlight">\(\hat{\gamma}=g(\hat{\boldsymbol{\theta}})\)</span>, para <span class="math notranslate nohighlight">\(g(\cdot)\)</span> continua y diferenciable.</p></li>
</ul>
</section>
<section id="inferencia">
<h2>Inferencia.<a class="headerlink" href="#inferencia" title="Permalink to this heading">#</a></h2>
<p>Consideramos ahora un test o prueba para inferencia estadística en el contexto de ML. Si bien bajo la premisa que la función de verosimilitud es conocida se pueden emplear varios test, algunos de ellos asintóticamente equivalentes, nos enfocaremos en el test de razón de versimilitud ( <em>Likelihood Ratio TEST</em> ) ya que en muchos casos es fácil de calcular.</p>
<p>Sea <span class="math notranslate nohighlight">\(\hat{\theta}_{u}\)</span> el vector de parámetros que se obtendría al maximizar (el log de) la función de verosimilitud sin la restricción impuesta en la hipótesis nula, <span class="math notranslate nohighlight">\(\text{ln }L(\theta)\)</span>. Sea <span class="math notranslate nohighlight">\(\widetilde{\theta}_{r}\)</span> el vector de parámetros que se obtendría al maximizar (el log de) la función de verosimilitud sujeta a la restricción (por ejemplo, <span class="math notranslate nohighlight">\(\widetilde{\theta}_{r}-\lambda'(r-R\beta)\)</span>). El estadístico Razón de Verosimilitudes (LR) estará definido por</p>
<div class="math notranslate nohighlight">
\[LR=-2[\ell(\widetilde{\theta}_{r})-\ell(\hat{\theta}_{u})]\sim\chi^2_q\]</div>
<p>La idea del test es que si la hipótesis nula es verdadera, <span class="math notranslate nohighlight">\(\ell(\widetilde{\theta}_{r})\)</span> y <span class="math notranslate nohighlight">\(\ell(\hat{\theta}_{u})\)</span> deberían ser iguales. En otras palabras, se evalúa si la diferencia entre ambas log-likelihood functions es significativa desde un punto de vista estadístico.</p>
</br>
<center><figure>
    <img alt="../../_images/LR.png" src="../../_images/LR.png" width="60%" height="60%"style="margin: 15px 0 0 0">
    <figcaption>Figura: Ilustración del test LR.</figcaption>
</figure></center>
</br>
</br>
<hr>
</section>
<section id="ejemplos">
<h2>Ejemplos.<a class="headerlink" href="#ejemplos" title="Permalink to this heading">#</a></h2>
</br>
<p><strong>Ejemplo 1 (sobre la notación vista).</strong> Supongamos <span class="math notranslate nohighlight">\(z_i\sim i.i.d.\,\mathbb{N}(\mu,1)\)</span> para <span class="math notranslate nohighlight">\(i=1,...,n\)</span>. De forma equivalente, diremos que la distribución de probabilidad es <span class="math notranslate nohighlight">\(\phi(w_i)\)</span>, para <span class="math notranslate nohighlight">\(w_i=(z_i-\mu)\)</span> y <span class="math notranslate nohighlight">\(\phi(w_i)=(2\pi)^{-1/2}exp(-w_i^2/2)\)</span> ; es decir, la distribución normal estándar (distribución gaussiana). Por ende, en este caso, la notación que empleamos correspondería a:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\theta=\mu\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(f(\boldsymbol{w};\boldsymbol{\theta})=f(w_1,...,w_n;\mu)=\Pi_{i=1}^n{\phi(w_i)}\)</span></p></li>
</ul>
<p>en donde <span class="math notranslate nohighlight">\(\phi(\cdot)\)</span> es la distribución nomal estandar.</p>
<p>Así, el estimador máximo verosímil (ML) estará dado por</p>
<div class="math notranslate nohighlight">
\[\hat{\mu}_{MLE}=\text{arg max}_{\mu}\,\left(\sum_{i=1}^n{log\,\phi(z_i-\mu)}\right)=\text{arg max}_{\mu}\,\left(-\frac{n\cdot log(2\pi)}{2}-\sum_{i=1}^n{\frac{(z_i-\mu)^2}{2}}\right)\]</div>
<p>al resolver,</p>
<div class="math notranslate nohighlight">
\[\hat{\mu}_{MLE}=\bar{z}=\frac{\sum_i z_i}{n}\]</div>
</br>
<hr>
</br>
<p><strong>Ejemplo 2. NLRM ( <em>Normal Linear Regression Model</em> )</strong> Supongamos un modelo de regresión lineal como el visto en <em>OLS</em> : <span class="math notranslate nohighlight">\(Y=X\beta+u\)</span> . El conjunto de datos es <span class="math notranslate nohighlight">\(w_i=(Y_i,X_i)\)</span> para <span class="math notranslate nohighlight">\(i=1,...,n\)</span> y el vector de parámetros es <span class="math notranslate nohighlight">\(\boldsymbol{\theta}=(\boldsymbol{\beta},\sigma^2)=(\beta_1,...,\beta_k,\sigma^2)\)</span>. Bajo el supuesto que <span class="math notranslate nohighlight">\((Y-X\boldsymbol{\beta})=u\sim\,\mathbb{N}(0,\sigma^2I_n)\)</span>, los estimadores ML están definidos por</p>
<div class="math notranslate nohighlight">
\[(\hat{\boldsymbol{\beta}},\hat{\sigma}^2)_{MLE}=\text{arg max}_{(\boldsymbol{\beta}\in\mathbb{R}^k,\sigma^2&gt;0)}\,\left(-\frac{n\cdot log(2\pi\sigma^2)}{2}-\frac{(Y-X\boldsymbol{\beta})'(Y-X\boldsymbol{\beta})}{2\sigma^2}\right)\]</div>
<p>es decir, la log-likelihood es</p>
<div class="math notranslate nohighlight">
\[\ell(\boldsymbol{\theta})=-\frac{n\cdot log(2\pi\sigma^2)}{2}-\frac{(\boldsymbol{y}-\boldsymbol{X}\boldsymbol{\beta})'(\boldsymbol{y}-\boldsymbol{X}\boldsymbol{\beta})}{2\sigma^2}\]</div>
<p>al resolver (es decir, a partir de las condiciones de primer orden <em>F.O.C.</em> evaluadas en el estimador ML),</p>
<div class="math notranslate nohighlight">
\[\hat{\boldsymbol{\beta}}_{MLE}=(X'X)^{-1}(X'Y) \hspace{0.5cm};\hspace{0.5cm}\hat{\sigma}^2_{MLE}=(Y-X\hat{\boldsymbol{\beta}})'(Y-X\hat{\boldsymbol{\beta}})n^{-1}\]</div>
<p>Notar que la expresión para <span class="math notranslate nohighlight">\(\beta\)</span> corresponde a la misma que se obtiene por OLS.</p>
<p>Además, después de resolver, se obtiene la siguiente matriz de información</p>
<div class="math notranslate nohighlight">
\[\begin{split}I(\boldsymbol{\beta}_0)=
\left[\begin{array}{cc}
\frac{1}{\sigma_0^2}(X'X) &amp; 0\\
0 &amp; \frac{N}{2\sigma_0^4}
\end{array}\right]\end{split}\]</div>
<p>Esta expresión es empleada para los errores estándar.</p>
<p></br></br></p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content\Ch3_MLE"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="Intro_MLE.html"
       title="página anterior">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">anterior</p>
        <p class="prev-next-title">3. Máxima Verosimilitud</p>
      </div>
    </a>
    <a class="right-next"
       href="computer/pract_mle_r.html"
       title="siguiente página">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">siguiente</p>
        <p class="prev-next-title">Rincón de Práctica R</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contenido
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimador">Estimador</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#errores-estandar-distribucion-asintotica">Errores estándar (distribución asintótica)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inferencia">Inferencia.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ejemplos">Ejemplos.</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Por Luis Chancí
</p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=ac02cc09edc035673794"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=ac02cc09edc035673794"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>