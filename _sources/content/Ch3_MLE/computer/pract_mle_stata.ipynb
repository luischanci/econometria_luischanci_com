{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2357cc",
   "metadata": {},
   "source": [
    "# Rincón de Práctica Stata\n",
    "\n",
    "## MLE usando Stata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d346ea5d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Ejemplo 1.\n",
    "\n",
    "Sea $\\epsilon_i\\sim i.i.d.\\, N(\\mu,\\sigma^2)$. \n",
    "\n",
    "1. Planear la función log-verosimilitud.\n",
    "2. Realizar en el computador simulación de 100 datos con $\\mathbb{N}(\\mu_0,\\sigma_0^2)=\\mathbb{N}(1.7,3^2)$ y estimación ML.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab427ab0",
   "metadata": {},
   "source": [
    "**Respuesta propuesta.**\n",
    "Como vimos, la log-likelihood function estará dada por \n",
    "\n",
    "$$\\ell(\\boldsymbol{\\theta})=-\\frac{n\\cdot log(2\\pi)}{2}-\\frac{n\\cdot log(\\sigma^2)}{2}-\\sum_{i=1}^N{\\frac{(\\epsilon_i-\\mu)^2}{2\\cdot \\sigma^2}}$$\n",
    "\n",
    "Así, una propuesta a la parte computacional en Stata sería la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f0d0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ipystata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a55145af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of observations (_N) was 0, now 100.\n",
      "\n",
      "    Variable |        Obs        Mean    Std. dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "         eps |        100    1.516204    3.095611  -12.11381    8.02918\n",
      "\n",
      "  1.   args lnf mu sigma\n",
      "  2.   quie replace `lnf' = -0.5*ln(2*_pi*`sigma'^2)-($ML_y1 - `mu')^2/(2*`sigma'^2)\n",
      "  3.   end\n",
      "\n",
      "initial:       log likelihood =     -<inf>  (could not be evaluated)\n",
      "feasible:      log likelihood = -2126.5089\n",
      "rescale:       log likelihood = -279.44898\n",
      "rescale eq:    log likelihood = -260.90153\n",
      "Iteration 0:   log likelihood = -260.90153  \n",
      "Iteration 1:   log likelihood = -254.80682  \n",
      "Iteration 2:   log likelihood = -254.39028  \n",
      "Iteration 3:   log likelihood = -254.38986  \n",
      "Iteration 4:   log likelihood = -254.38986  \n",
      "\n",
      "                                                           Number of obs = 100\n",
      "                                                           Wald chi2(0)  =   .\n",
      "Log likelihood = -254.38986                                Prob > chi2   =   .\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "mu           |\n",
      "       _cons |   1.516204   .3080094     4.92   0.000     .9125165    2.119891\n",
      "-------------+----------------------------------------------------------------\n",
      "sigma        |\n",
      "       _cons |   3.080094   .2177955    14.14   0.000     2.653223    3.506965\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "  * 1. Simular datos \n",
    "  set    seed 123\n",
    "  set    obs  100\n",
    "  scalar mu    = 1.7\n",
    "  scalar sigma = 3\n",
    "  \n",
    "  gen eps = rnormal(mu,sigma)\n",
    "  sum eps\n",
    "\n",
    "  * 2. Escribir la función log-likelihood\n",
    "  cap prog drop my_mle\n",
    "  pro def my_mle\n",
    "\t  args lnf mu sigma\n",
    "\t  quie replace `lnf' = -0.5*ln(2*_pi*`sigma'^2)-($ML_y1 - `mu')^2/(2*`sigma'^2)\n",
    "  end\n",
    "  \n",
    "  * 3. Optimizar la log-likelihood\n",
    "  ml model lf my_mle (mu: eps=)(sigma: eps=)\n",
    "  ml max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8994d",
   "metadata": {},
   "source": [
    "</br>\n",
    "<hr>\n",
    "\n",
    "### Ejemplo 2. \n",
    "\n",
    "**Bajo normalidad, MLE y OLS dan el mismo vector estimado de parámetros para el modelo lineal.** \n",
    "\n",
    "Sea,\n",
    "\n",
    "$$Y=\\boldsymbol{X}\\boldsymbol{\\beta}+u \\hspace{0.5cm};\\hspace{0.5cm}u_i\\sim N(0,\\sigma^2)$$\n",
    "\n",
    "1. Planear la función log-verosimilitud\n",
    "2. Encontrar $\\hat{\\boldsymbol{\\theta}}_{MLE}=(\\hat{\\boldsymbol{\\beta}},\\hat{\\sigma}^2)$\n",
    "3. Encontrar la matriz de información\n",
    "4. Realizar en el computador simulación de 100 datos para $y_i=\\beta_0+\\beta_1x_{1i}+\\beta_2x_{2i}+u_i$, donde $x_1\\sim U[0,10]$, $x_2\\sim\\chi^2_1$, $u_i\\sim\\mathbb{N}(0,\\sigma^2=3^2)$ y $\\boldsymbol{\\beta}'=(\\beta_0,\\beta_1,\\beta_2)'=(1,0.75,3.2)$. Realizar estimación ML de los parámetros y comparar con OLS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca540d8",
   "metadata": {},
   "source": [
    "**Respuesta sugerida.**\n",
    "\n",
    "Como vimos, para $\\boldsymbol{x}=(1,X_1,x_2)'$ y $u_i=y_i-\\boldsymbol{x}_i'\\boldsymbol{\\beta}$ con $\\boldsymbol{\\beta}'=(\\beta_0,\\beta_1,\\beta_2)'$ se tiene que\n",
    "\n",
    "$$\\ell(\\boldsymbol{\\theta})=-\\frac{n\\cdot log(2\\pi\\sigma^2)}{2}-\\frac{(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta})'(\\boldsymbol{y}-\\boldsymbol{X}\\boldsymbol{\\beta})}{2\\sigma^2}$$\n",
    "\n",
    "y a partir de las condiciones de primer orden (_F.O.C._) evaluadas en el estimador ML, se obtiene: \n",
    "$$\\hat{\\boldsymbol{\\beta}}_{MLE}=(X'X)^{-1}(X'Y)\\hspace{0.5cm},\\hspace{0.5cm}\\hat{\\sigma}^2_{MLE}=(Y-X\\hat{\\beta})'(Y-X\\hat{\\beta})\\cdot n^{-1}$$ \n",
    "\n",
    "Notar que la expresión para $\\beta$ corresponde a la misma que se obtiene por OLS.\n",
    "\n",
    "Además, después de resolver, se obtiene la siguiente matriz de información\n",
    "\n",
    "$$I(\\boldsymbol{\\beta}_0)=\n",
    "\\left[\\begin{array}{cc}\n",
    "\\frac{1}{\\sigma_0^2}(X'X) & 0\\\\\n",
    "0 & \\frac{N}{2\\sigma_0^4}\n",
    "\\end{array}\\right]$$\n",
    "\n",
    "Así, una propuesta para el código de programación en Stata es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a5ffab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of observations (_N) was 100, now 100.\n",
      "\n",
      "  1.     args lnf Xb sigma\n",
      "  2.     quie replace `lnf' = ln(normalden($ML_y1,`Xb',`sigma'))\n",
      "  3.     end\n",
      "\n",
      "initial:       log likelihood =     -<inf>  (could not be evaluated)\n",
      "feasible:      log likelihood = -822.51142\n",
      "rescale:       log likelihood =  -348.3095\n",
      "rescale eq:    log likelihood =  -348.3095\n",
      "Iteration 0:   log likelihood =  -348.3095  (not concave)\n",
      "Iteration 1:   log likelihood = -305.30761  \n",
      "Iteration 2:   log likelihood = -272.72806  \n",
      "Iteration 3:   log likelihood = -251.69736  \n",
      "Iteration 4:   log likelihood = -251.33146  \n",
      "Iteration 5:   log likelihood = -251.33126  \n",
      "Iteration 6:   log likelihood = -251.33126  \n",
      "\n",
      "                                                        Number of obs =    100\n",
      "                                                        Wald chi2(2)  = 445.22\n",
      "Log likelihood = -251.33126                             Prob > chi2   = 0.0000\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "           y | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "xb           |\n",
      "          x1 |   .8781539   .1068187     8.22   0.000     .6687931    1.087515\n",
      "          x2 |   3.229557   .1698408    19.02   0.000     2.896675    3.562439\n",
      "       _cons |   .2802955   .6265632     0.45   0.655    -.9477458    1.508337\n",
      "-------------+----------------------------------------------------------------\n",
      "sigma        |\n",
      "       _cons |   2.987312   .2112349    14.14   0.000       2.5733    3.401325\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "      Source |       SS           df       MS      Number of obs   =       100\n",
      "-------------+----------------------------------   F(2, 97)        =    215.93\n",
      "       Model |  3973.17594         2  1986.58797   Prob > F        =    0.0000\n",
      "    Residual |  892.403429        97  9.20003535   R-squared       =    0.8166\n",
      "-------------+----------------------------------   Adj R-squared   =    0.8128\n",
      "       Total |  4865.57937        99  49.1472664   Root MSE        =    3.0332\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "           y | Coefficient  Std. err.      t    P>|t|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "          x1 |   .8781539   .1084579     8.10   0.000     .6628949    1.093413\n",
      "          x2 |   3.229557   .1724472    18.73   0.000     2.887297    3.571817\n",
      "       _cons |   .2802955   .6361785     0.44   0.660    -.9823427    1.542934\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%stata\n",
    "  * 1. Simular datos \n",
    "    set seed 123\n",
    "    set obs  100\n",
    "\n",
    "    scalar sigma = 3\n",
    "\n",
    "    gen x1 = runiform(0,10)\n",
    "    gen x2 = rchi2(1)\n",
    "    gen u  = rnormal(0,sigma)\n",
    "\n",
    "    gen y = 1 + 0.75*x1 + 3.2*x2 + u\n",
    "\n",
    "  * 2. Escribir la función log-likelihood\n",
    "    cap prog drop my_ols\n",
    "    pro def my_ols\n",
    "\t    args lnf Xb sigma\n",
    "\t    quie replace `lnf' = ln(normalden($ML_y1,`Xb',`sigma'))\n",
    "    end\n",
    "\n",
    "  * 3. Optimizar la log-likelihood\n",
    "    ml model lf my_ols (xb: y = x1 x2)(sigma:)\n",
    "    ml max\n",
    "  \n",
    "  * 4. Comparación con OLS\n",
    "    reg y x1 x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b112a-1341-4d16-b055-97134bb82b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
